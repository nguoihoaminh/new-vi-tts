<p align="left">
  <img src="https://cdn-uploads.huggingface.co/production/uploads/63d8d8879dfcfa941d4d7cd9/GsQKdaTyn2FFx_cZvVHk3.png" alt="Logo">
</p>

# EraX-Smile-Female-F5-V1.0: Giving F5-TTS a Vietnamese Twist (with Online Zero-Shot Voice Cloning!) ‚ú®

Hey there, fellow Vietnamese AI explorers! üëã

We introduce **EraX-Smile-Female-F5-V1.0**, a Vietnamese text-to-speech model developed based on the F5-TTS architecture [arXiv:2410.06885](https://arxiv.org/abs/2410.06885).
To adapt this model for Vietnamese, we utilized a substantial dataset combining over 800,000 samples, of which some are from public repositories and with an extensive 500-hour private dataset, for which we gratefully acknowledge obtaining usage rights. 
The model underwent significant training, involving approximately 1 million update steps on a 4x RTX 3090 configuration. It tooks almost a week with some crashes and burns too üî•

Our hope is that EraX-Smile-Female-F5-V1.0 (soon UniSex) proves to be a useful contribution to the community for ethical and creative purposes.

## Does it actually work? Let's listen! üéß

Okay, moment of truth. Here's a sample voice we fed into the model (the "reference"):

# EraX-Smile-Female-F5-V1.0

## Reference Audio (< 15s) & Text
**Reference Audio:** [Download and play reference audio](https://huggingface.co/erax-ai/EraX-Smile-Female-F5-V1.0/resolve/main/update_213000_ref.wav)

**Reference Text:**
> *"Th·∫≠m ch√≠ kh√¥ng ƒÉn th√¨ c≈©ng c√≥ c·∫£m gi√°c r·∫•t l√† c·ª©ng b·ª•ng, ch·ªß y·∫øu l√† c√°i ph·∫ßn r·ªën...tr·ªü l√™n. Em c√≥ c·∫£m gi√°c kh√≥ th·ªü, v√† ng·ªß c≈©ng kh√¥ng ngon, th∆∞·ªùng b·ªã ·ª£ h∆°i r·∫•t l√† nhi·ªÅu"*

And here's our model trying its best to mimic that voice while reading completely different text. Fingers crossed! ü§û

## Text to Generate
> *"Trong khi ƒë√≥, t·∫°i m·ªôt chung c∆∞ tr√™n ƒë·ªãa b√†n P.Vƒ©nh Tuy (Q.Ho√†ng Mai), nhi·ªÅu ng∆∞·ªùi s·ªëng tr√™n t·∫ßng cao gi·∫≠t m√¨nh khi th·∫•y rung l·∫Øc m·∫°nh n√™n ƒë√£ ch·∫°y xu·ªëng s·∫£nh t·∫ßng 1. C∆∞ d√¢n t·∫°i ƒë√¢y cho bi·∫øt, h·ªç ch∆∞a bao gi·ªù c·∫£m th·∫•y ·∫£nh h∆∞·ªüng c·ªßa ƒë·ªông ƒë·∫•t m·∫°nh nh∆∞ h√¥m nay"*

**Generated Audio:** [Download and play generated audio](https://huggingface.co/erax-ai/EraX-Smile-Female-F5-V1.0/resolve/main/generated_429000.wav)

## Attention: 
Just a gentle observation regarding the selected reference audio ‚Äì it seems there might be a **noticeable pause** within it. Please be aware that the zero-shot cloning process will likely replicate this characteristic in the synthesized output. If a more continuous flow without pauses is desired, you might consider using a reference recording that is clean and free of significant delays, unless reproducing the pause is intentional.

## Audio Samples

If you'd like to listen to the audio samples directly:

1. **Reference Audio**: Download the [reference audio file](https://huggingface.co/erax-ai/EraX-Smile-Female-F5-V1.0/resolve/main/model/update_213000_ref.wav) and play it on your device.

2. **Generated Audio**: Download the [generated audio file](https://huggingface.co/erax-ai/EraX-Smile-Female-F5-V1.0/resolve/main/model/generated_429000.wav) and play it on your device.

Alternatively, you can visit our [Hugging Face model page](https://huggingface.co/erax-ai/EraX-Smile-Female-F5-V1.0) to access and play these audio files directly.

## Wanna try this magic (or madness) yourself? üßô‚Äç‚ôÇÔ∏è

Getting started is hopefully not *too* painful. After downloading this repo and cloning our GitHub, you can try something like this:

```python
# Ubuntu: sudo apt install ffmpeg
# Windows please refer to https://www.geeksforgeeks.org/how-to-install-ffmpeg-on-windows/

import os
os.environ["CUDA_VISIBLE_DEVICES"] =  "0" # Tell it which GPU to use (or ignore if you're CPU-bound and patient!)

from vinorm import TTSnorm # Gotta normalize that Vietnamese text first
from f5tts_wrapper import F5TTSWrapper # Our handy wrapper class

# --- Config ---
# Path to the model checkpoint you downloaded from *this* repo
# MAKE SURE this path points to the actual .pth or .ckpt file!
eraX_ckpt_path = "path/to/your/downloaded/EraX-Smile-Female-F5-V1.0/model.pth" # <-- CHANGE THIS!

# Path to the voice you want to clone
ref_audio_path = "path/to/your/reference_voice.wav" # <-- CHANGE THIS!

# Path to the vocab file from this repo
vocab_file = "path/to/your/downloaded/EraX-Smile-Female-F5-V1.0/vocab.txt" # <-- CHANGE THIS!

# Where to save the generated sound
output_dir = "output_audio"

# --- Texts ---
# Text matching the reference audio (helps the model learn the voice). Please make sure it match with the referrence audio!
ref_text = "Th·∫≠m ch√≠ kh√¥ng ƒÉn th√¨ c≈©ng c√≥ c·∫£m gi√°c r·∫•t l√† c·ª©ng b·ª•ng, ch·ªß y·∫øu l√† c√°i ph·∫ßn r·ªën...tr·ªü l√™n. Em c√≥ c·∫£m gi√°c kh√≥ th·ªü, v√† ng·ªß c≈©ng kh√¥ng ngon, th∆∞·ªùng b·ªã ·ª£ h∆°i r·∫•t l√† nhi·ªÅu"

# The text you want the cloned voice to speak
text_to_generate = "Trong khi ƒë√≥, t·∫°i m·ªôt chung c∆∞ tr√™n ƒë·ªãa b√†n P.Vƒ©nh Tuy (Q.Ho√†ng Mai), nhi·ªÅu ng∆∞·ªùi s·ªëng tr√™n t·∫ßng cao gi·∫≠t m√¨nh khi th·∫•y rung l·∫Øc m·∫°nh n√™n ƒë√£ ch·∫°y xu·ªëng s·∫£nh t·∫ßng 1. C∆∞ d√¢n t·∫°i ƒë√¢y cho bi·∫øt, h·ªç ch∆∞a bao gi·ªù c·∫£m th·∫•y ·∫£nh h∆∞·ªüng c·ªßa ƒë·ªông ƒë·∫•t m·∫°nh nh∆∞ h√¥m nay."

# --- Let's Go! ---
print("Initializing the TTS engine... (Might take a sec)")
tts = F5TTSWrapper(
    vocoder_name="vocos", # Using Vocos vocoder
    ckpt_path=eraX_ckpt_path,
    vocab_file=vocab_file,
    use_ema=False, # ALWAYS False as we converted from .pt to safetensors and EMA (where there is or not) was in there
)

# Normalize the reference text (makes it easier for the model)
ref_text_norm = TTSnorm(ref_text)

# Prepare the output folder
os.makedirs(output_dir, exist_ok=True)

print("Processing the reference voice...")
# Feed the model the reference voice ONCE
# Provide ref_text for better quality, or set ref_text="" to use Whisper for auto-transcription (if installed)
tts.preprocess_reference(
    ref_audio_path=ref_audio_path,
    ref_text=ref_text_norm,
    clip_short=True # Keeps reference audio to a manageable length (~12s)
)
print(f"Reference audio duration used: {tts.get_current_audio_length():.2f} seconds")

# --- Generate New Speech ---
print("Generating new speech with the cloned voice...")

# Normalize the text we want to speak
text_norm = TTSnorm(text_to_generate)

# You can generate multiple sentences easily
# Just add more normalized strings to this list
sentences = [text_norm]

for i, sentence in enumerate(sentences):
    output_path = os.path.join(output_dir, f"generated_speech_{i+1}.wav")

    # THE ACTUAL GENERATION HAPPENS HERE!
    tts.generate(
        text=sentence,
        output_path=output_path,
        nfe_step=20,               # Denoising steps. More = slower but potentially better? (Default: 32)
        cfg_strength=2.0,          # How strongly to stick to the reference voice style? (Default: 2.0)
        speed=1.0,                 # Make it talk faster or slower (Default: 1.0)
        cross_fade_duration=0.15,  # Smooths transitions if text is split into chunks (Default: 0.15)
    )
    print(f"Boom! Audio saved to: {output_path}")

print("\nAll done! Check your output folder.")
```
* For full Web interface and control with Gradio, please clone and use the original repository of [F5-TTS Github](https://github.com/SWivid/F5-TTS)
* We use the cool library from [Vinorm Team](https://github.com/v-nhandt21/Vinorm) for Vietnamese text normalization.

* **What's Next?** ü§î
The EraX Team (that's us!) are always tinkering and trying to make things better (or at least, less broken!).
We hope to bring more updates your way. Let us know what you think ‚Äì feedback, bug reports, or even just saying hi is always welcome!
- [ ] ‚≠ê Release checkpoints for Vietnamese male
- [ ] üìù Codes for real-time TTS streaming
- [ ] üî• Release Piper-based model that can run on ...Rasberry Pi 4 üî•

‚ö†Ô∏è **Important Note on Responsible Use** ‚ö†Ô∏è
- Voice cloning technology is powerful and comes with significant ethical responsibilities.
- Intended Use: This model is intended for creative purposes, accessibility tools, personal projects, and applications where consent is explicit and ethical considerations are prioritized.
- **Prohibited Use**: We strongly condemn and strictly prohibit the use of this model for any malicious or unethical purposes, including but not limited to:
  - Creating non-consensual deepfakes or impersonating individuals without permission.
  - Generating misinformation, fraudulent content, or defamatory material.
  - Harassment, abuse, or any form of criminal activity.
- User Responsibility: By using this model, you agree to do so responsibly and ethically. You are solely responsible for the content you generate and ensuring it complies with all applicable laws and ethical standards. The creators (EraX Team) disavow any responsibility for misuse of this model.

  Please use this technology thoughtfully and ethically.

‚ö†Ô∏è **L∆∞u √Ω Quan tr·ªçng v·ªÅ Vi·ªác S·ª≠ d·ª•ng c√≥ Tr√°ch nhi·ªám** ‚ö†Ô∏è

- S·ª©c m·∫°nh v√† Tr√°ch nhi·ªám: C√¥ng ngh·ªá nh√¢n b·∫£n gi·ªçng n√≥i s·ªü h·ªØu s·ª©c m·∫°nh to l·ªõn v√† ƒëi k√®m v·ªõi nh·ªØng tr√°ch nhi·ªám ƒë·∫°o ƒë·ª©c h·∫øt s·ª©c quan tr·ªçng.
- M·ª•c ƒë√≠ch S·ª≠ d·ª•ng D·ª± ki·∫øn: M√¥ h√¨nh n√†y ƒë∆∞·ª£c t·∫°o ra nh·∫±m ph·ª•c v·ª• c√°c m·ª•c ƒë√≠ch s√°ng t·∫°o, ph√°t tri·ªÉn c√¥ng c·ª• h·ªó tr·ª£ ti·∫øp c·∫≠n, th·ª±c hi·ªán d·ª± √°n c√° nh√¢n v√† c√°c ·ª©ng d·ª•ng kh√°c n∆°i c√≥ s·ª± ƒë·ªìng thu·∫≠n r√µ r√†ng t·ª´ c√°c b√™n li√™n quan v√† c√°c y·∫øu t·ªë ƒë·∫°o ƒë·ª©c lu√¥n ƒë∆∞·ª£c ƒë·∫∑t l√™n h√†ng ƒë·∫ßu.
- Nghi√™m c·∫•m S·ª≠ d·ª•ng Sai tr√°i: Ch√∫ng t√¥i c·ª±c l·ª±c l√™n √°n v√† nghi√™m c·∫•m tuy·ªát ƒë·ªëi vi·ªác s·ª≠ d·ª•ng m√¥ h√¨nh n√†y cho b·∫•t k·ª≥ m·ª•c ƒë√≠ch x·∫•u xa, phi ƒë·∫°o ƒë·ª©c n√†o, bao g·ªìm nh∆∞ng kh√¥ng gi·ªõi h·∫°n ·ªü:
  - T·∫°o ra deepfake ho·∫∑c m·∫°o danh ng∆∞·ªùi kh√°c khi ch∆∞a ƒë∆∞·ª£c s·ª± cho ph√©p ho·∫∑c ƒë·ªìng thu·∫≠n r√µ r√†ng.
  - Ph√°t t√°n th√¥ng tin sai l·ªách, t·∫°o n·ªôi dung l·ª´a ƒë·∫£o ho·∫∑c c√°c t√†i li·ªáu mang t√≠nh ph·ªâ b√°ng, b√¥i nh·ªç.
  - Th·ª±c hi·ªán h√†nh vi qu·∫•y r·ªëi, l·∫°m d·ª•ng ho·∫∑c b·∫•t k·ª≥ ho·∫°t ƒë·ªông t·ªôi ph·∫°m n√†o kh√°c.

- Tr√°ch nhi·ªám c·ªßa Ng∆∞·ªùi d√πng: Khi s·ª≠ d·ª•ng m√¥ h√¨nh n√†y, b·∫°n cam k·∫øt h√†nh ƒë·ªông m·ªôt c√°ch c√≥ tr√°ch nhi·ªám v√† tu√¢n th·ªß c√°c chu·∫©n m·ª±c ƒë·∫°o ƒë·ª©c. B·∫°n ph·∫£i ch·ªãu tr√°ch nhi·ªám ho√†n to√†n v·ªÅ n·ªôi dung do m√¨nh t·∫°o ra v√† ƒë·∫£m b·∫£o r·∫±ng n·ªôi dung ƒë√≥ tu√¢n th·ªß m·ªçi quy ƒë·ªãnh ph√°p lu·∫≠t hi·ªán h√†nh v√† c√°c ti√™u chu·∫©n ƒë·∫°o ƒë·ª©c. ƒê·ªôi ng≈© ph√°t tri·ªÉn (Nh√≥m EraX) ho√†n to√†n kh√¥ng ch·ªãu tr√°ch nhi·ªám cho b·∫•t k·ª≥ h√†nh vi l·∫°m d·ª•ng n√†o ƒë·ªëi v·ªõi m√¥ h√¨nh n√†y.

  L·ªùi k√™u g·ªçi: Xin h√£y s·ª≠ d·ª•ng c√¥ng ngh·ªá n√†y m·ªôt c√°ch c√≥ suy x√©t, th·∫≠n tr·ªçng v√† ƒë·∫°o ƒë·ª©c.

**License Stuff** üìú
We're keeping it simple with the MIT License, following in the footsteps of giants like Whisper. Use it, break it, hopefully make cool things with it!

**Feeling Generous? (Citation)** üôè
Did this model actually help you? Or maybe just provide a moment's amusement? If so, a star ‚≠ê on our GitHub repo would totally make our day!
Don't forget to like, share and star us on Github and HuggingFace!
And if you're writing something fancy (like a research paper) and want to give us a nod, here's the bibtex snippet:

```bibtex
@misc{EraXSmileF5_2024,
  author       = {Nguy·ªÖn Anh Nguy√™n and The EraX Team},
  title        = {EraX-Smile-Female-F5-V1.0: Ng∆∞·ªùi Vi·ªát s√†nh ti·∫øng Vi·ªát.},
  year         = {2024},
  publisher    = {Hugging Face},
  journal      = {Hugging Face Model Hub},
  howpublished = {\url{https://github.com/EraX-JS-Company/EraX-Smile-F5TTS}}
}
```
